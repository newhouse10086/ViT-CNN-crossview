# FSRA-MAT: Multi-Modal Adaptive Transformer Configuration
# 学术创新架构配置文件

model:
  name: "FSRA_MAT"
  num_classes: 701
  
  # 创新模块配置
  input_dim: 768                    # 输入特征维度
  geo_dim: 256                      # 几何特征维度
  sem_dim: 512                      # 语义特征维度
  max_regions: 6                    # 最大动态区域数
  
  # 几何感知位置编码
  geometry_aware_pe:
    enabled: true
    max_len: 5000
    use_scale_embedding: true
    use_rotation_embedding: true
    use_distance_embedding: true
  
  # 层次化注意力融合
  hierarchical_attention:
    num_scales: 4                   # 多尺度层数
    num_heads: 8                    # 注意力头数
    dropout: 0.1
  
  # 动态区域对齐
  dynamic_alignment:
    adaptive_regions: true          # 启用自适应区域生成
    min_regions: 3
    max_regions: 6
    region_importance_threshold: 0.1
  
  # 视觉-语言跨模态
  vision_language:
    enabled: true                   # 启用多模态
    text_encoder: "sentence-transformers/all-MiniLM-L6-v2"
    text_dim: 384
    hidden_dim: 768
    max_text_length: 128

data:
  data_dir: "data"
  batch_size: 8                     # 适中的批量大小
  num_workers: 4
  image_height: 256                 # 标准图像尺寸
  image_width: 256
  
  # 地理位置文本描述（创新点）
  use_location_descriptions: true
  description_templates: [
    "University campus with {building_type} and {landscape}",
    "Urban area with {structure_type} and {facilities}",
    "Academic complex with {academic_buildings}",
    "{location_type} district with {distinctive_features}"
  ]

training:
  num_epochs: 100
  learning_rate: 0.0005             # 较低学习率适合复杂模型
  weight_decay: 0.0001
  momentum: 0.9
  
  # 多阶段学习率调度
  scheduler:
    type: "MultiStepLR"
    milestones: [30, 60, 85]
    gamma: 0.1
  
  # 损失函数权重
  loss_weights:
    global_loss: 1.0
    regional_loss: 0.5
    consistency_loss: 0.2           # 时序一致性损失
    alignment_loss: 0.3             # 区域对齐损失
    multimodal_loss: 0.4            # 多模态对齐损失

# 创新实验设置
experiments:
  # 对比方法
  baselines: [
    "original_fsra",
    "geodtr_plus", 
    "garet",
    "etq_matcher"
  ]
  
  # 消融实验
  ablation_studies:
    - "no_geometric_decoupling"     # 移除几何解耦
    - "no_hierarchical_attention"   # 移除层次化注意力
    - "no_dynamic_alignment"        # 移除动态对齐
    - "no_vision_language"          # 移除视觉-语言模块
    - "fixed_regions"               # 使用固定区域（类似原始FSRA）
  
  # 泛化性能测试
  cross_dataset_evaluation: true
  datasets: [
    "University-1652",
    "VIGOR", 
    "CVUSA",
    "custom_multimodal"
  ]

# 创新评估指标
evaluation:
  metrics: [
    "recall_at_1",
    "recall_at_5", 
    "recall_at_10",
    "average_precision",
    "cross_area_generalization",    # 跨区域泛化能力
    "noise_robustness",             # 抗噪声能力
    "scale_invariance",             # 尺度不变性
    "rotation_invariance"           # 旋转不变性
  ]
  
  # 可视化输出
  visualization:
    attention_maps: true            # 注意力可视化
    region_alignment: true          # 区域对齐可视化
    multimodal_alignment: true      # 多模态对齐可视化
    failure_case_analysis: true     # 失败案例分析

# 系统配置
system:
  gpu_ids: "0"
  mixed_precision: true             # 使用混合精度训练
  gradient_checkpointing: true      # 梯度检查点节省内存
  
# 论文实验记录
paper_experiments:
  title: "FSRA-MAT: Multi-Modal Adaptive Transformer for Cross-View Geo-Localization"
  
  main_contributions: [
    "首次提出几何-语义解耦的跨视角定位方法",
    "设计动态区域对齐算法超越固定分割策略", 
    "引入视觉-语言跨模态增强地理理解能力",
    "实现层次化多尺度注意力融合机制"
  ]
  
  expected_improvements:
    recall_at_1: "+15.2%"
    average_precision: "+12.8%"
    cross_area_generalization: "+20.3%"
    noise_robustness: "+18.5%" 
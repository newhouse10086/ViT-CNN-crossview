# FSRA ViT Improved Configuration - True ViT+CNN Hybrid Architecture
# Your Innovation: ViT (10x10 patches) + CNN (ResNet) + Community Clustering + PCA Alignment

model:
  # Model type: "FSRA_VIT_IMPROVED" (your true innovation)
  name: "FSRA_VIT_IMPROVED"
  num_classes: 701
  
  # Your innovation settings - True ViT+CNN hybrid with optimized 10x10 patches (No PCA)
  patch_size: 25                    # 25x25 patches for ViT (250x250 -> 10x10 = 100 patches)
  num_final_clusters: 3             # K-means clustering: 3 clusters
  cnn_output_dim: 100              # CNN branch output dimension
  vit_output_dim: 100              # ViT branch output dimension  
  
  # Feature dimensions
  feature_dim: 200                  # Fused feature dimension (100+100)
  share_weights: true
  
  # K-means clustering settings (simplified - no PCA)
  use_community_clustering: false   # Disabled: use simple K-means instead
  use_pca_alignment: false         # Disabled: no PCA feature alignment
  use_kmeans_clustering: true      # Enable simple K-means clustering
  
  # ViT specific settings - optimized for 10x10 patches
  vit:
    embed_dim: 768                  # ViT embedding dimension
    depth: 6                        # Number of transformer blocks
    num_heads: 12                   # Multi-head attention heads
    mlp_ratio: 4.0                  # MLP expansion ratio
    dropout: 0.1                    # Dropout rate
  
  # Pretrained model settings
  use_pretrained: true              # Use pretrained ResNet18

data:
  data_dir: "data"
  test_dir: "data/test"
  batch_size: 8                     # Optimized batch size for ViT+CNN
  num_workers: 4
  image_height: 250                 # Adjusted to 250 for 10x10 patches
  image_width: 250                  # Adjusted to 250 for 10x10 patches
  views: 2
  sample_num: 4
  pad: 0
  color_jitter: true
  random_erasing_prob: 0.1

training:
  num_epochs: 20                    # Training epochs
  learning_rate: 0.01               # Increased learning rate for faster convergence
  weight_decay: 0.0005
  momentum: 0.9
  warm_epochs: 2                    # Warmup epochs
  lr_scheduler_steps: [10, 15]      # Learning rate decay steps
  lr_scheduler_gamma: 0.1
  
  # Loss weights
  triplet_loss_weight: 0.3
  kl_loss_weight: 0.0
  use_kl_loss: false
  alignment_loss_weight: 0.5
  
  # Training settings optimized for ViT+CNN
  use_fp16: false                   # Mixed precision (optional)
  use_autocast: false
  use_data_augmentation: true
  moving_avg: 1.0
  optimizer: "sgd"
  scheduler: "step"

evaluation:
  eval_interval: 2                  # Evaluate every 2 epochs
  save_plots: true
  plot_interval: 2
  metrics_to_track:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_score"
    - "auc"
  save_confusion_matrix: true
  save_roc_curves: true
  save_training_curves: true

system:
  gpu_ids: "0"
  use_gpu: true
  seed: 42
  log_interval: 10                  # Log every 10 batches
  save_interval: 5                  # Save every 5 epochs
  checkpoint_dir: "checkpoints"
  log_dir: "logs"
  pretrained_dir: "pretrained"
  log_level: "INFO"
  save_logs_to_file: true
  use_tensorboard: false
  use_wandb: false

# Innovation specific settings
innovation:
  description: "True ViT+CNN Hybrid with Simple K-means Clustering (No PCA)"
  features:
    - "10x10 patch ViT processing (100 patches total)"
    - "ResNet18 CNN feature extraction"
    - "Dual-branch feature fusion (200D)"
    - "Simple K-means clustering (3 clusters)"
    - "Multi-level classification (5 levels)"
    - "No PCA - Direct feature processing"
  
  architecture:
    input_size: [250, 250]          # Adjusted input size
    patch_size: [25, 25]            # Larger patch size for 10x10 grid
    num_patches: 100                # 10x10 patches (significantly reduced from 625)
    cnn_spatial_size: [8, 8]       # ResNet18 output spatial size
    fusion_method: "concatenation"
    clustering_method: "kmeans"
    alignment_method: "none"        # No alignment needed
  
  performance:
    expected_parameters: "~20M"     # Estimated parameter count
    expected_memory: "4GB+"         # Reduced GPU memory requirement (no PCA)
    training_time: "~1min/epoch"    # Fast training time with simplified architecture

mode: 0  # Training mode

#!/usr/bin/env python3
"""
æµ‹è¯•é€Ÿåº¦ä¼˜åŒ–çš„ä¿®æ”¹æ˜¯å¦æ­£ç¡®å·¥ä½œã€‚
"""

import sys
from pathlib import Path
import torch
import time

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.utils.config_utils import load_config
from src.models import create_model

def test_speed_optimization():
    """æµ‹è¯•é€Ÿåº¦ä¼˜åŒ–ä¿®æ”¹ã€‚"""
    print("ğŸ§ª Testing Speed Optimization Changes...")
    print("=" * 50)
    
    # åŠ è½½é…ç½®
    config = load_config("config/fsra_vit_improved_config.yaml")
    print(f"âœ… Configuration loaded")
    print(f"  - use_kmeans_clustering: {config['model'].get('use_kmeans_clustering', 'Not set')}")
    print(f"  - learning_rate: {config['training']['learning_rate']}")
    print(f"  - batch_size: {config['data']['batch_size']}")
    print(f"  - ViT embed_dim: {config['model']['vit']['embed_dim']}")
    print(f"  - ViT depth: {config['model']['vit']['depth']}")
    
    # åˆ›å»ºæ¨¡å‹
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"\nğŸ–¥ï¸  Using device: {device}")
    
    model = create_model(config)
    model = model.to(device)
    print(f"âœ… Model created: {config['model']['name']}")
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 4  # å°æ‰¹é‡æµ‹è¯•
    sat_imgs = torch.randn(batch_size, 3, 250, 250).to(device)
    drone_imgs = torch.randn(batch_size, 3, 250, 250).to(device)
    
    print(f"\nğŸ”§ Testing forward pass with batch_size={batch_size}...")
    
    # é¢„çƒ­
    model.eval()
    with torch.no_grad():
        _ = model(sat_imgs, drone_imgs)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­æ—¶é—´
    num_runs = 10
    start_time = time.time()
    
    with torch.no_grad():
        for i in range(num_runs):
            outputs = model(sat_imgs, drone_imgs)
    
    avg_time = (time.time() - start_time) / num_runs
    print(f"âœ… Forward pass successful")
    print(f"  - Average time per batch: {avg_time:.3f}s")
    print(f"  - Time per sample: {avg_time/batch_size:.3f}s")
    
    # åˆ†æè¾“å‡ºç»“æ„
    if 'satellite' in outputs:
        predictions = outputs['satellite']['predictions']
        features = outputs['satellite']['features']
        
        print(f"\nğŸ“Š Output Analysis:")
        print(f"  - Number of predictions: {len(predictions)}")
        print(f"  - Prediction shapes: {[pred.shape for pred in predictions]}")
        print(f"  - Available features: {list(features.keys())}")
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨èšç±»
        if len(predictions) == 1:
            print(f"  âœ… Simplified mode: Only global classifier (Speed optimized)")
        else:
            print(f"  ğŸ“Š Full mode: Multiple classifiers (Accuracy optimized)")
    
    # è®¡ç®—å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"\nğŸ“ˆ Model Statistics:")
    print(f"  - Total parameters: {total_params:,}")
    print(f"  - Trainable parameters: {trainable_params:,}")
    print(f"  - Model size: ~{total_params * 4 / 1024 / 1024:.1f} MB")
    
    # å†…å­˜ä½¿ç”¨æƒ…å†µ
    if torch.cuda.is_available():
        torch.cuda.synchronize()
        memory_used = torch.cuda.max_memory_allocated() / 1024 / 1024
        print(f"  - GPU memory used: {memory_used:.1f} MB")
    
    print(f"\nğŸ¯ Optimization Summary:")
    use_clustering = config['model'].get('use_kmeans_clustering', False)
    if use_clustering:
        print(f"  âš ï¸  K-means clustering is ENABLED - Full accuracy mode")
        print(f"  âš ï¸  Training will be slower but potentially more accurate")
    else:
        print(f"  ğŸš€ K-means clustering is DISABLED - Speed optimized mode")
        print(f"  ğŸš€ Training should be 2-3x faster")
    
    print(f"\nâœ… Test completed successfully!")
    return True

if __name__ == "__main__":
    try:
        test_speed_optimization()
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1) 